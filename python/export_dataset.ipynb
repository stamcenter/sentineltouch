{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dda5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torchvision\n",
    "\n",
    "if '__file__' in globals():\n",
    "    script_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    script_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(script_dir, './'))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.sokoto_dataset import SOKOTODataset\n",
    "from utils.polyu_dataset import PolyUDatasetContactless\n",
    "\n",
    "from utils.pca_module import pca_data_construction, pca_generation, pca_collate_fn\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4043c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "##################################    PolyU    ############################################\n",
    "###########################################################################################\n",
    "\n",
    "# train_transform = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize((0.5), (1.0)),\n",
    "# ])\n",
    "\n",
    "# polyu_location = \"./../images/Cross_Fingerprint_Images_Database/processed_contactless_2d_fingerprint_images\"\n",
    "# trainset = PolyUDatasetContactless(root_dir=polyu_location, type='train', transform=train_transform)\n",
    "# validationset = PolyUDatasetContactless(root_dir=polyu_location, type='val', transform=train_transform)\n",
    "\n",
    "\n",
    "# dataset_name = \"polyu\"\n",
    "# num_ids = 400\n",
    "\n",
    "# ###########################################################################################\n",
    "# ##################################    Sokoto    ###########################################\n",
    "# ###########################################################################################\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((96, 96)),\n",
    "    torchvision.transforms.Normalize((0.5), (1.0)),\n",
    "])\n",
    "\n",
    "scoofing_db = \"./../images/SCOOF_DB/SOCOFing/Real\"\n",
    "labels_file=\"./metadata/sokoto_meta.txt\"\n",
    "sokoto = SOKOTODataset(root_dir=scoofing_db, labels_file=labels_file, transform=train_transform)\n",
    "trainset, validationset = train_test_split(\n",
    "    sokoto, test_size=0.4, random_state=seed, shuffle=True\n",
    ")\n",
    "\n",
    "num_ids = 600\n",
    "dataset_name = \"sokoto\"\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "##################################    END    ##############################################\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b9ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlenet5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m x, y \u001b[38;5;241m=\u001b[39m pca_data_construction(trainset)\n\u001b[0;32m---> 10\u001b[0m x_pca, pca_model, total_pca, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mpca_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca_elements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(batch):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pca_collate_fn(\n\u001b[1;32m     14\u001b[0m         batch,\n\u001b[1;32m     15\u001b[0m         pca_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         return_components\u001b[38;5;241m=\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/MachineLearning/sentineltouch/python/utils/pca_module.py:35\u001b[0m, in \u001b[0;36mpca_generation\u001b[0;34m(x_input, scaler, pca_components)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Step 2: Apply PCA with desired number of components\u001b[39;00m\n\u001b[1;32m     34\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mpca_components)\n\u001b[0;32m---> 35\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Step 3: Explained variance summary\u001b[39;00m\n\u001b[1;32m     38\u001b[0m  \u001b[38;5;66;03m# Step 3: Explained variance summary\u001b[39;00m\n\u001b[1;32m     39\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_ \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:454\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:548\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    538\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# Use scipy.linalg with NumPy/SciPy inputs for the sake of not\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;66;03m# introducing unanticipated behavior changes. In the long run we\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m# solver by default though (assuming both are built against the\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# same BLAS).\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(X, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/QIF/lib/python3.12/site-packages/scipy/linalg/_decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pca_elements = 784\n",
    "pca_elements = 0.95\n",
    "\n",
    "new_size = (28, 28)\n",
    "\n",
    "model_type = \"lenet5\"\n",
    "\n",
    "x, y = pca_data_construction(trainset)\n",
    "x_pca, pca_model, total_pca, scaler = pca_generation(x, StandardScaler(), pca_elements)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return pca_collate_fn(\n",
    "        batch,\n",
    "        pca_model,\n",
    "        scaler,\n",
    "        new_size,\n",
    "        return_components=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader = DataLoader(\n",
    "    validationset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"../exported_images\"\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(SAVE_PATH, dataset_name, model_type, \"register\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_PATH, dataset_name, model_type, \"authenticate\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_to_csv(path, img):\n",
    "    # if image is 1d, just save to single row of values\n",
    "    # if image is 2d, save to multiple rows\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if img.ndim == 1:\n",
    "            writer.writerow(img)\n",
    "        elif img.ndim == 2:\n",
    "            for row in img:\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3762454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_to_csv(dataloader, type = \"register\"):\n",
    "    for sample_num, (img, label) in tqdm(enumerate(dataloader)):\n",
    "        # Process each image in the validation set\n",
    "        img = img.numpy()\n",
    "        label = label.numpy()\n",
    "\n",
    "        if img.ndim == 2:\n",
    "            img = img[0]\n",
    "        else:\n",
    "            img = img[0][0]\n",
    "\n",
    "        # Save the image and label to a CSV file\n",
    "        save_image_to_csv(\n",
    "            os.path.join(SAVE_PATH, dataset_name, model_type, type, f\"{sample_num}_{label[0]}.csv\"), \n",
    "            img\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03497a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:00, 76.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:02, 65.85it/s]\n",
      "160it [00:02, 62.01it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dataset_to_csv(validation_loader, type=\"register\")\n",
    "save_dataset_to_csv(validation_loader, type=\"authenticate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QIF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
